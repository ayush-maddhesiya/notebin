import { B2Client } from "./client";
import * as fs from "fs";
import * as util from "util";
import request = require("request");
import zlib = require("zlib");
import split = require("split");
import stream = require("stream");
import { B2Meta } from "./meta";

const writeFile = util.promisify(fs.writeFile);
const readFile = util.promisify(fs.readFile);

export interface SnapshotItem {
  id: string;
  revision: string;
}

export interface ArchiveMeta {
  providers: ArchiveProvider[];
  remotes: ArchiveRemote[];
}

export interface ArchiveProvider {
  id: string;
  path: string;
}

export interface ArchiveRemote {
  name: string;
  endpoint: string;
}

export interface B2ArchiveFileProviderMeta {
  id: string;
  objects: number;
}

export interface B2ArchiveFileMeta {
  providers: B2ArchiveFileProviderMeta[];
}

export interface B2ArchiveApplyResult {
  result: {
    applied: number;
    skipped: number;
  };
  providerResults: {
    id: string;
  }[];
}

export class B2ArchiveFile {
  private path: string;
  private meta: B2ArchiveFileMeta;
  constructor(path: string) {
    this.path = path;
  }

  async inspect(forceReload: boolean = false): Promise<B2ArchiveFileMeta> {
    if (!forceReload && this.meta) {
      return this.meta;
    }

    const meta: B2ArchiveFileMeta = {
      providers: []
    };

    await this.walkObjects(data => {
      let p = meta.providers.find(p => p.id === data.id);
      if (!p) {
        p = {
          id: data.id,
          objects: 0
        };
        meta.providers.push(p);
      }
      p.objects++;
    });

    return meta;
  }

  async walkObjects(fn: (obj: { id: string }) => void) {
    const gunzip = zlib.createGunzip();
    const ts = new stream.Transform({
      transform(chunk, encoding, callback) {
        fn(chunk as any);
        callback(null, chunk);
      },
      objectMode: true
    });
    return new Promise((resolve, reject) => {
      fs.createReadStream(this.path)
        .pipe(gunzip)
        .on("error", reject)
        .pipe(split(JSON.parse, null, { trailing: false }) as stream.Transform)
        .on("error", reject)
        .pipe(ts)
        .on("error", reject)
        .on("data", () => {})
        .on("end", function() {
          resolve();
        });
    });
  }

  async transformAndPipe(fn: (obj: { id: string }) => any, w: stream.Writable) {
    const gunzip = zlib.createGunzip();
    const gzip = zlib.createGzip();
    const ts = new stream.Transform({
      transform(chunk, encoding, callback) {
        callback(null, JSON.stringify(fn(chunk as any)) + "\n");
      },
      objectMode: true
    });
    return new Promise((resolve, reject) => {
      fs.createReadStream(this.path)
        .pipe(gunzip)
        .on("error", reject)
        .pipe(split(JSON.parse, null, { trailing: false }) as stream.Transform)
        .on("error", reject)
        .pipe(ts)
        .on("error", reject)
        .pipe(gzip)
        .on("error", reject)
        .pipe(w)
        .on("error", reject)
        .on("end", function() {
          resolve();
        });
    });
  }

  async getTypes(): Promise<{ [key: string]: string }> {
    const meta = await readFile(`${this.path}.metadata.json`, "utf8");
    return JSON.parse(meta)["source"]["types"];
  }
}

export type ProviderIdRewriteFunc = (id: string) => string;

function getModuleIdTypeMap(meta: B2Meta): { [key: string]: string } {
  const idModuleMap: { [key: string]: string } = {};
  Object.keys(meta.allModules).forEach(type => {
    const insts = meta.allModules[type];
    insts.forEach(inst => {
      if (inst.id) {
        idModuleMap[inst.id] = type;
      }
    });
  });
  return idModuleMap;
}

export class B2Archive {
  private c: B2Client;
  private path: string;

  constructor(client: B2Client) {
    this.c = client;
    this.path = `/archive`;
  }

  async inspect(): Promise<ArchiveMeta> {
    try {
      const [providers, remotes] = await Promise.all([
        this.c.request("GET", `${this.path}/provider`),
        this.c.request("GET", `${this.path}/remote`)
      ]);
      return {
        providers,
        remotes
      };
    } catch (e) {
      if (e.status === 404) {
        throw new Error("Archive module was not found");
      } else {
        throw e;
      }
    }
  }

  private async writeMetaFile(path: string, metadata: any) {
    const filepath = path + ".metadata.json";
    return writeFile(
      filepath,
      JSON.stringify(
        {
          source: {
            endpoint: this.c.endpoint,
            types: getModuleIdTypeMap(await this.c.inspect())
          },
          metadata
        },
        null,
        "  "
      ),
      "utf8"
    );
  }

  /** Export all data to archive file */
  async exportArchive(archivePath: string, providers: string[] = null) {
    await new Promise((resolve, reject) => {
      request({
        url: `${this.c.endpoint}${this.path}/export`,
        qs: this.c.configureQuery(
          providers
            ? {
                provider: providers
              }
            : {}
        ),
        useQuerystring: true
      } as any)
        .on("error", reject)
        .pipe(fs.createWriteStream(archivePath))
        .on("error", reject)
        .on("finish", () => {
          resolve();
        });
    });

    const af = new B2ArchiveFile(archivePath);
    const meta = await af.inspect();
    await this.writeMetaFile(archivePath, meta);
  }

  private async getRedirectChecker() {
    const meta = await this.c.inspect();
    const idModuleMap = getModuleIdTypeMap(meta);
    return (id: string, type: string) => {
      if (!id) {
        throw new Error(
          `Invalid archive file, some object does not have an id`
        );
      }

      if (!type) {
        throw new Error(
          `Invalid archive file, an invalid type '${type}' was found`
        );
      }

      if (!(id in idModuleMap)) {
        return;
      }
      const moduleType = idModuleMap[id];
      if (moduleType !== type) {
        throw new Error(
          `Can not push data to provider '${id}', type in archive is '${type}' but B2 expects type '${moduleType}'`
        );
      }
    };
  }

  /** Import data from archive file */
  async importArchive(
    archivePath: string,
    redirect: ProviderIdRewriteFunc = id => id
  ): Promise<B2ArchiveApplyResult> {
    const checkType = await this.getRedirectChecker();
    const a = new B2ArchiveFile(archivePath);
    const types = await a.getTypes();
    return new Promise<B2ArchiveApplyResult>((resolve, reject) => {
      let rejected = false;
      const tryReject = (err: any) => {
        if (rejected) {
          return;
        }
        rejected = true;
        reject(err);
      };
      const req = request
        .put({
          url: `${this.c.endpoint}${this.path}/apply`,
          qs: this.c.configureQuery({})
        })
        .on("response", res => {
          let body = "";
          res
            .on("error", tryReject)
            .on("data", (data: Buffer) => {
              body += data.toString("utf8");
            })
            .on("end", () => {
              if (res.statusCode !== 200) {
                return tryReject({
                  message: `${res.statusMessage}`,
                  body
                });
              }

              try {
                return resolve(JSON.parse(body));
              } catch (e) {
                return tryReject(e);
              }
            });
        });

      a.transformAndPipe(obj => {
        if (obj.id !== "auth" && obj.id.indexOf("asset:") !== 0) {
          checkType(obj.id, types[obj.id]);
          obj.id = redirect(obj.id);
        }
        return obj;
      }, req as any).then(null, tryReject);
    });
  }
}
